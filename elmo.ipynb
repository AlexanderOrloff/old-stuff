{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏ –ø–æ —ç–ª–º–æ –æ—Ç –ê–Ω–¥—Ä–µ—è –ö—É—Ç—É–∑–æ–≤–∞](https://github.com/ltgoslo/simple_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elmo_helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-01a5713f91cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0melmo_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_elmo_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_elmo_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elmo_helpers'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from elmo_helpers import tokenize, get_elmo_vectors, load_elmo_embeddings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "elmo_path = 'elmo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bilm\n",
      "  Downloading https://files.pythonhosted.org/packages/22/a6/711e6ea5a05f7ce72f0a5c6c3bfbd1451aeb8810c9ec8074d5667e3ff433/bilm-0.1.post5-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in c:\\users\\asus\\anaconda3\\lib\\site-packages (from bilm) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from h5py->bilm) (1.16.4)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\anaconda3\\lib\\site-packages (from h5py->bilm) (1.12.0)\n",
      "Installing collected packages: bilm\n",
      "Successfully installed bilm-0.1.post5\n"
     ]
    }
   ],
   "source": [
    "!pip install bilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from bilm import Batcher, BidirectionalLanguageModel, weight_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "2 sentences total\n",
      "=====\n",
      "[['—Ö–æ—á—É', '–∏–∑—É—á–∏—Ç—å', '—Ç–µ—Ö–Ω–∏–∫—É', '—Å—Ç—Ä–µ–ª—å–±—ã', '–∏–∑', '–ª—É–∫–∞'], ['–º–æ–∂–µ—à—å', '–Ω–∞—Ä–µ–∑–∞—Ç—å', '–º–µ–ª–∫–æ', '–ª—É–∫', '–≤–æ–∑—å–º–∏', '–¥–ª—è', '—ç—Ç–æ–≥–æ', '–±–æ–ª—å—à–æ–π', '–Ω–æ–∂']]\n"
     ]
    }
   ],
   "source": [
    "raw_sentences = [\n",
    "    '—Ö–æ—á—É –∏–∑—É—á–∏—Ç—å —Ç–µ—Ö–Ω–∏–∫—É —Å—Ç—Ä–µ–ª—å–±—ã –∏–∑ –ª—É–∫–∞',\n",
    "    '–º–æ–∂–µ—à—å –Ω–∞—Ä–µ–∑–∞—Ç—å –º–µ–ª–∫–æ –ª—É–∫, –≤–æ–∑—å–º–∏ –¥–ª—è —ç—Ç–æ–≥–æ –±–æ–ª—å—à–æ–π –Ω–æ–∂'\n",
    "]\n",
    "\n",
    "sentences = [tokenize(s) for s in raw_sentences]\n",
    "    \n",
    "print('=====')\n",
    "print('%d sentences total' % len(sentences))\n",
    "print('=====')\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/ksen/Desktop/PROJECTS/–ü–æ–∏—Å–∫üé∑/2019/infosearch/3 Semantics/simple_elmo/bilm/model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/ksen/Desktop/PROJECTS/–ü–æ–∏—Å–∫üé∑/2019/infosearch/3 Semantics/simple_elmo/bilm/model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences in this batch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.622628927230835\n",
      "ELMo embeddings for your input are ready\n",
      "Tensor shape: (2, 9, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Loading a pre-trained ELMo model:\n",
    "batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(elmo_path)\n",
    "\n",
    "\n",
    "# Actually producing ELMo embeddings for our data:\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # It is necessary to initialize variables once before running inference.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    start = time.time()\n",
    "    elmo_vectors = get_elmo_vectors(\n",
    "        sess, sentences, batcher, sentence_character_ids, elmo_sentence_input)\n",
    "    \n",
    "    print(time.time() - start)\n",
    "    print('ELMo embeddings for your input are ready')\n",
    "    print('Tensor shape:', elmo_vectors.shape)\n",
    "    \n",
    "    # Due to batch processing, the above code produces for each sentence\n",
    "    # the same number of token vectors, equal to the length of the longest sentence\n",
    "    # (the 2nd dimension of the elmo_vector tensor).\n",
    "    # If a sentence is shorter, the vectors for non-existent words are filled with zeroes.\n",
    "    # Let's make a version without these redundant vectors:\n",
    "    \n",
    "    cropped_vectors = []\n",
    "    for vect, sent in zip(elmo_vectors, sentences):\n",
    "        cropped_vector = vect[:len(sent), :]\n",
    "        cropped_vectors.append(cropped_vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query sentence: ['—Ö–æ—á—É', '–∏–∑—É—á–∏—Ç—å', '—Ç–µ—Ö–Ω–∏–∫—É', '—Å—Ç—Ä–µ–ª—å–±—ã', '–∏–∑', '–ª—É–∫–∞']\n",
      "Query word: –ª—É–∫–∞\n",
      "======\n",
      "['–º–æ–∂–µ—à—å', '–Ω–∞—Ä–µ–∑–∞—Ç—å', '–º–µ–ª–∫–æ', '–ª—É–∫', '–≤–æ–∑—å–º–∏', '–¥–ª—è', '—ç—Ç–æ–≥–æ', '–±–æ–ª—å—à–æ–π', '–Ω–æ–∂']\n",
      "–ª—É–∫ 155.8144\n",
      "–Ω–æ–∂ 150.87787\n",
      "—ç—Ç–æ–≥–æ 93.784744\n",
      "–º–µ–ª–∫–æ 88.479836\n",
      "–Ω–∞—Ä–µ–∑–∞—Ç—å 85.494\n",
      "–±–æ–ª—å—à–æ–π 79.993164\n",
      "–≤–æ–∑—å–º–∏ 70.24108\n",
      "–º–æ–∂–µ—à—å 55.802162\n",
      "–¥–ª—è 50.650307\n"
     ]
    }
   ],
   "source": [
    "# A quick test:\n",
    "# in each sentence, we find the tokens most similar to the 2nd token of the first sentence\n",
    "\n",
    "query_nr = 5\n",
    "query_word = sentences[0][query_nr]\n",
    "print('Query sentence:', sentences[0])\n",
    "print('Query word:', query_word)\n",
    "\n",
    "query_vec = cropped_vectors[0][query_nr]\n",
    "\n",
    "\n",
    "for sent_nr, sent in enumerate(sentences):\n",
    "    if sent_nr == 0:\n",
    "        continue\n",
    "        \n",
    "    print('======')\n",
    "    print(sent)\n",
    "    sims = {}\n",
    "    \n",
    "    for nr, word in enumerate(sent):\n",
    "        w_vec = cropped_vectors[sent_nr][nr]\n",
    "        sims[word] = np.dot(query_vec, w_vec)\n",
    "\n",
    "    for k in sorted(sims, key=sims.get, reverse=True):\n",
    "        print(k, sims[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
